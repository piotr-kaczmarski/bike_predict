---
title: "Model Step 2 - Model Metrics"
date: "`r lubridate::date(lubridate::now(tzone = 'EST'))`"
output: html_document
params:
    name: sam.edwardes/bike_predict_model_r
    version: NULL
---

```{r setup, include=FALSE}
library(tidyverse)
library(vetiver)
library(pins)
library(yardstick)
library(glue)

knitr::opts_chunk$set(echo = FALSE)
```

```{r load_data}
board <- pins::board_rsconnect()
v <- vetiver_pin_read(board, params$name, version = params$version)
v_meta <- pin_meta(board, params$name)

con <- odbc::dbConnect(odbc::odbc(), "Content DB", timeout = 10)
bike_model_data <- tbl(con, "bike_model_data")

train_start_date <- lubridate::as_date(v$metadata$user$train_dates[1])
train_end_date <- lubridate::as_date(v$metadata$user$train_dates[2])
test_start_date <- lubridate::as_date(v$metadata$user$test_dates[1])
test_end_date <- lubridate::as_date(v$metadata$user$test_dates[2])

data <- bike_model_data %>%
  filter(date >= train_start_date) %>%
  collect() %>%
  mutate(
    data_type = case_when(
      date <= train_end_date ~ "train",
      date <= test_end_date ~ "test",
      TRUE ~ "latest"
    )
  )

train_data <- data %>%
  filter(data_type == "train")

test_data <- data %>%
  filter(data_type == "test")
```

```{r compute_metrics, include=FALSE}
## compute predictions for your evaluation data
## `handler_startup` is designed to get the R process ready to make predictions
suppressPackageStartupMessages(handler_startup(v))

# Specifically load the packages required by the model. Check 
# `v$metadata$required_pkgs` to see the required pacakges. These packages must
# be specicially defined so that RStudio Connect knows to install them when
# deploying this document.
library(parsnip)
library(ranger)
library(recipes)
library(workflows)
library(slider)

preds <- augment(v, test_data)

latest_metrics <- preds %>%
  arrange(date) %>%
  vetiver_compute_metrics(
    date_var = date,
    period = "day",
    truth = n_bikes,
    estimate = .pred
  )

pin_name <- "sam.edwardes/bike-predict-model-metrics"

if (pin_exists(board, pin_name)) {
  print("Pin already exists, updating existing pin...")
  vetiver_pin_metrics(board, latest_metrics, pin_name, overwrite = TRUE)
} else {
  print("Creating metrics pin for the first time...")
  pin_write(board, latest_metrics, pin_name)
}
```

This documents monitors the model performance on a daily basis. Below is a summary of the key model metrics including:

- Root Mean Squared Error (RMSE),
- R Squared (RSQ), and
- Mean Absolute Error (MAE).

```{r all_time_metrics_plot}
all_time_metrics <- pin_read(board, pin_name)

vetiver_plot_metrics(all_time_metrics) +
  labs(
    title = "Model Metrics",
    size = "Number of\nObservations"
  )
```
